{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RNN\n",
    "\n",
    "- 변수간 순서가 있는 경우 유용\n",
    "  * 그림의 화살표는 파라미터라고 이해하면 됨\n",
    "  * 모든 모델은 동일 (반복되는 구조)\n",
    "\n",
    "![](./img/09_rnn.JPG)\n",
    "\n",
    "## RNN이 사용되는 텍스트 \"감성분석\" 예제\n",
    "\n",
    "- 문장은 단어로 구성되며 단어의 순서가 주요\n",
    "- 감성분석 : 긍정/부정 classification 모델\n",
    "\n",
    "- 기존에는 document term matrix를 구성하여 분류 모델 구축\n",
    "  - 문장의 순서를 고려하지 못함 <br/><br/>\n",
    "  \n",
    "- 순서를 고려한 모델링 $\\rightarrow$ 모델의 파라미터가 너무 많아짐\n",
    "  - 서로 다른 길이의 문장을 고려하지 못함 <br/><br/>\n",
    "\n",
    "- **RNN 적용**\n",
    "  - 순서를 고려할 수 있는 RNN 모델 적용 시, 현재의 정보를 미래에 반영 가능\n",
    "  - 각 단어를 one-hot vector로 표기하여 input으로 넣어줌 (예: '나는' = 1,0,0,0,0,0)\n",
    "  \n",
    "  - 실제로는 dense-layer의 형태로 되어 있음\n",
    "\n",
    "![](./img/09_rnn_2.JPG)\n",
    "\n",
    "## RNN 알고리즘\n",
    "\n",
    "- Recurrent neural networks share the same parameters(U,V,W) across all time steps.\n",
    "![](./img/09_rnn_algo.JPG)\n",
    "\n",
    "\n",
    "- $x_{t}$ : input at time step $ t \\in \\mathbb{R}^{m}$\n",
    "- $s_{t}$ : hidden sate at time step $ t \\in \\mathbb{R}^{n}$\n",
    "- $y_{t}$ : output at time step $ t \\in \\mathbb{R}^{l}$\n",
    "- $U \\in \\mathbb{R}^{n \\times  m}$\n",
    "- $V \\in \\mathbb{R}^{l \\times  n}$\n",
    "- $W \\in \\mathbb{R}^{n \\times  n}$\n",
    "\n",
    "- Hidden : $S_{t} = tanh(U_{x_{t}} + W_{S_{t-1}}$\n",
    "- Output : $softmax(V_{S_{t-1}}$\n",
    "- Loss function : $L(y, \\hat{y}) = \\sum_{t} L_{t}(y, \\hat{y}) = - \\sum_{t}y_{t} ln \\hat{y}_{t}$ (if classfication problem : cross entropy) \n",
    "\n",
    "![](./img/09_rnn_algo_02.JPG)\n",
    "\n",
    "\n",
    "## Back Propagation in RNN\n",
    "\n",
    "- Back Propagation Through Time (BPTT) 알고리즘\n",
    "- RNN의 파라미터 U, V, W를 업데이트\n",
    "\n",
    "1) $\\frac{\\partial L_{t}}{\\partial V} = \\frac{\\partial L_{t}}{\\partial \\hat{y}_{t}} \\times \\frac{\\partial \\hat{y}_{t}}{\\partial V_{s_{t}}} \\times \\frac{\\partial V_{s_{t}}}{\\partial V}$ <br/>\n",
    "2) $\\frac{\\partial L_{t}}{\\partial W} \n",
    "  = \\sum^{t}_{k=0} (\\frac{\\partial L}{\\partial \\hat{y}_{t}} \\times \n",
    "    \\frac{\\partial \\hat{y}_{t}}{\\partial s_{t}} \\times \n",
    "    \\frac{\\partial s_{t}}{\\partial s_{k}} \\times \n",
    "    \\frac{\\partial s_{k}}{\\partial W})$ <br/>\n",
    "3) $\\frac{\\partial L_{t}}{\\partial U} = \\sum^{t}_{k=0} (\\frac{\\partial L}{\\partial \\hat{y}_{t}} \\times \n",
    "    \\frac{\\partial \\hat{y}_{t}}{\\partial s_{t}} \\times \n",
    "    \\frac{\\partial s_{t}}{\\partial s_{k}} \\times \n",
    "    \\frac{\\partial s_{k}}{\\partial U})$ <br/>\n",
    "\n",
    "\n",
    "#### BPTT 예제\n",
    "\n",
    "- 전달 과정의 gradient 를 모두 sum 해줌\n",
    "- 마지막 결과의 output을 최종 classficiation 결과로 가져가게 됨\n",
    "\n",
    "![](./img/09_brtt.JPG)\n",
    "\n",
    "\n",
    "## RNN 의 한계\n",
    "\n",
    "- 길이가 긴 sequence의 경우, exploding gradient / vanishing gradient 문제가 발생하기 쉬움 (layer를 많이 쌓지 않아도)\n",
    "- Exploding gradient : clip gradient\n",
    "- Vanishing gradient problem 을 극복하기 위해 : 다른 모델 사용 (LSTM, GRU)\n",
    "\n",
    "![](./img/09_rnn_cons.JPG)\n",
    "\n",
    "## 1. LSTM\n",
    "\n",
    "> Hochreiter, S., & Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8), 1735-1780. <br/>\n",
    "> http://www.bioinf.jku.at/publications/older/2604.pdf\n",
    "\n",
    "- Long Short-Term Memory\n",
    "- Gate(스위치) 개념을 추가하여 길이가 가니 sequence 를 모델링\n",
    "- 다양한 변형 모델이 존재\n",
    "\n",
    "![](./img/09_lstm.JPG)\n",
    "![](./img/09_lstm_02.JPG)\n",
    "<br/><br/>\n",
    "\n",
    "- Simple RNN 구조 (과거의 정보를 무조건 다음으로 넘겨줌)\n",
    "![](./img/09_lstm_03.JPG)\n",
    "\n",
    "- LSTM의 연결 구조\n",
    "\n",
    "![](./img/09_lstm_04.JPG)\n",
    "\n",
    "\n",
    "## 2. LSTM 의 단계\n",
    "\n",
    "### 0) $C_{t}$ : cell state\n",
    "\n",
    "![](./img/09_lstm_cell_state.JPG)\n",
    "\n",
    "### 1) $f_{c}$ : forget gate & $i_{t}$ : input gate \n",
    "- 과거의 cell state 정보 $C_{t-1}$을 얼마나 받아 들일지 결정\n",
    "- $I_{t}$ : cell state $C_{t}$ 에 과거 시점의 입력과 출력을 얼마나 반영할 것인지 결정\n",
    "\n",
    "- forget gate\n",
    "![](./img/09_lstm_forget_gate.JPG)\n",
    "\n",
    "- input gate\n",
    "![](./img/09_lstm_input_gate.JPG)\n",
    "\n",
    "### 2) Update $C_{t}$ : cell state (정보량)\n",
    "- $\\widetilde{C_{t}}$ : 과거 시점의 출력 $(h_{t-1})$ 과 현재 입력 $(x_{t})$ 정보를 이용해 현재 시점의 $C_{t}$ 업데이트 \n",
    "  - 다음셀로 보낼 정보량  <br/>\n",
    "\n",
    "![](./img/09_lstm_f_i.JPG)\n",
    "\n",
    "### 3) $o_{t}$ & $h_{t}$ : output gate\n",
    "\n",
    "- 과거 시점의 출력 $(h_{t-1})$ 과 현재 입력 $(x_{t})$ 정보와 $C_{t}$를 조합하여 출력 $h_t$ 생산\n",
    "\n",
    "![](./img/09_lstm_update_cell_state.JPG)\n",
    "\n",
    "### LSTM의 변형\n",
    "- Peehole connections\n",
    "- GRU : gated recurrent unit\n",
    "\n",
    "\n",
    "## 3. GRU\n",
    "\n",
    "- GRU : Gated recurrent unit 은 LSTM의 변형 버전\n",
    "- $C_{t}$ 를 업데이트 할 때, forget gate만으로 구성\n",
    "\n",
    "![](./img/09_gru.JPG)\n",
    "\n",
    "\n",
    "## RNN을 이용한 다양한 모델링\n",
    "\n",
    "> http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "\n",
    "![](./img/09_rnn_models.JPG)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
