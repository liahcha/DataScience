{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "\n",
    "* 뇌의 뉴런간 연결을 묘사한 인공신경망 기반의 모델\n",
    "* 최근 5년간 급격한 학문적 발전과 동시에 많은 관심을 받고 있음\n",
    "\n",
    "![](./img/01_deep_learning.png)\n",
    "\n",
    "\n",
    "\n",
    "## Deep Learning 의 역사\n",
    "\n",
    "* Deep learning 의 역사 = Artificial Neural Network 의 역사\n",
    "* 2006년 Hinton에 의해 많은 레이어를 학습할 수 있게 됨과 동시에 성능향상을 이룸\n",
    "* 이전에는 2개 이상의 레이어 학습이 불가능\n",
    "![](./img/02_dl_history.png)\n",
    "\n",
    "\n",
    "## Machine Learning & Deep Learning\n",
    "\n",
    "* Deep learning 은 machine learning 에 속하는 방법론 중 하나\n",
    "\n",
    "![](./img/02_ml_dl.png)\n",
    "\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "* 학습데이터로부터 함수 F를 찾는 방법론\n",
    "* 종속변수 Y가 범주형이면 classification, 연속형이면 regression <br/><br/>\n",
    "$Y=F(X)$ <br/>\n",
    "\n",
    "  * X: 독립변수, 입력변수\n",
    "  * Y: 종속변수, 출력변수\n",
    "<br/><br/>\n",
    "* Supervised Learning Models\n",
    "  * SVM\n",
    "  * Decision Tree\n",
    "  * Logistric Regression\n",
    "  * Random Forest\n",
    "\n",
    "<hr/>\n",
    "\n",
    "## Deep Neural Network\n",
    "\n",
    "* 왜 여러 개의 레이어를 쌓으려고 하는가?\n",
    "  * High level abstraction : 상위 레이어로 갈 수록 데이터 변화에 강건한 변수를 생성\n",
    "  * Distributed representation : 각 유닛이 일반화된 변수를 학습\n",
    "  * Deep learning = feature (representation) learning\n",
    "  <br/><br/>  \n",
    "* 레이어를 늘리면? \n",
    "  * 레이어 수를 늘렸더니 실패 : Hidden 레이어의 수가 1개 이상만 되어도 overfitting 발생\n",
    "  * 모델 학습을 잘하기 위한 다른 전략 필요\n",
    "\n",
    "![](./img/02_dnn.png)\n",
    "<br/>\n",
    "\n",
    "## 딥러닝 모델 학습의 어려움\n",
    "\n",
    "* **Vanishing gradient** : 상위 레이어의 학습이 다른 레이어 보다 먼저 끝난 경우 gradient 가 하우 레이어로 전파 되지 않음 \n",
    "* Gradient 의 크기가 0으로 수렴하여 모델의 파라미터를 더 이상 업데이트 하지 못함\n",
    "\n",
    "![](./img/02_vanishing.png)\n",
    "\n",
    "\n",
    "<hr/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "## Pre-training\n",
    "\n",
    ">*Hinton, G.E., & Salakhutdinov, R. R. (2006). Reducing the dimensionality of data with neural networks. science, 313(5786), 504-507*\n",
    "\n",
    "* RBM (restricted Boltzmann machine) 을 이용한 pre-training\n",
    "* RBM: Y를 이용하지 않는 unsupervised learning 으로 데이터의 분포를 모델링 하는 기법\n",
    "* 각 레이어의 파라미터 초기값을 잘 설정하여 좋은 성능 달성\n",
    "* Hinton이 방법론을 제안한 이후 딥러닝의 시대 개막\n",
    "![](./img/02_pre_training.png)\n",
    "\n",
    ">*Erhan, D., Bengio, Y., Courville, A., Manzagol, P.A., Vincent, P., & Bengio, S. (2010). Why does unsupervised pre-training hep deep learning?. Journal of Machine Learning Research, 11(Feb), 625-660*\n",
    "\n",
    "* Pre-training 을 이용하여 레이어가 많아도 효과적으로 학습할 수 있음\n",
    "* 레이어의 수가 적은 경우에도 pre-training은 효과적임\n",
    "* Pre-training을 통해 성능도 우수하며 강건한 예측 성능을 달성 가능\n",
    "\n",
    "![](./img/02_pre_training_02.png)\n",
    "\n",
    "\n",
    "## Dropout\n",
    "\n",
    ">*Srivastava, N., Hinton, G.E., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine Learning Research, 15(1), 1929-1958*\n",
    "\n",
    "* Pre-training 없이 신경망 모델을 간단하게 학습할 수 있는 방법\n",
    "* 학습 과정 중에 무작위로 hidden 레이어의 유닛이 없다고 간주\n",
    "* Sparse representation = 복잡도가 낮은 모델 (regularization)\n",
    "* Vanishing gradient 문제의 해결 (하위 레이어도 잘 학습)\n",
    "* Dropout 비율 : 주로 0.5~0.8 사이의 값 이용\n",
    "![](./img/02_dropout_01.png)\n",
    "\n",
    "![](./img/02_dropout_02.png)\n",
    "\n",
    "<hr/>\n",
    "## 딥러닝은 과연 만능인가?\n",
    "\n",
    "* 딥러닝도 의사결정나무, 로지스틱 회귀분석, SVM 등과 같은 기계학습 모델 중 하나\n",
    "* 다른 모델과 같이 성능이 데이터의 품질에 크게 의존\n",
    "* 문제 상황에 맞는 다양한 learning 기법을 이용해야 함 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
