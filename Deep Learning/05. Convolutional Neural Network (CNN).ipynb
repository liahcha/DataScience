{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 데이터\n",
    "\n",
    "- color 이미지는 RGB 행렬로 분해 가능\n",
    "  - 흑백 이미지는 단일 행렬 변환 가능\n",
    "- 각각의 행렬은 색의 농담을 실수 값으로 표현\n",
    "  - 8 bit : 1~256\n",
    "  - 16 bit : 1~65536\n",
    "  ![](./img/05_rgb_02.png)\n",
    "  ![](./img/05_rgb.png)\n",
    "  <br/>\n",
    "\n",
    "## 인공신경망을 이용한 이미지 분류 모델링\n",
    "\n",
    "- 각각의 픽셀을 하나의 변수로 간주하여 모델링 (변수독립 가정)\n",
    "- $N_{1} = 400 * 700 * 3 = 840,000$\n",
    "- $N_{2}$ 의 크기도 변수의 수에 맞춰서 정함 -> $(840,000 * N_{2})$ 파라미터 -> 학습이 어렵다\n",
    "  ![](./img/05_modeling.png)\n",
    "  <br/>\n",
    "\n",
    "## 기존 이미지 분류 모델링\n",
    "\n",
    "- 변수의 수를 줄이기 위해 low level 변수(픽셀)를 조합하여 보다 적은 수의 변수를 생성\n",
    "- Feature engineering : 도메인 지식을 이용하여 feature생성\n",
    "- Feature extraction : 기계학습 알고리즘으로 feature 생성\n",
    "\n",
    "\n",
    "## 이미지의 특성\n",
    "\n",
    "- 이미지의 경우 인접 변수(픽셀)간 높은 상관관계를 가짐 (spatially-local correlation)\n",
    "- 이미지의 부분적 특성 (e.g. 눈, 귀)은 고정된 위치에 등장하지 않음 (invariant feature)\n",
    "- 데이터의 특성을 반영한 모델을 구성하면 성능이 좋아지지 않을까?\n",
    "![](./img/05_feature.png)\n",
    "<br/>\n",
    "\n",
    "\n",
    "## 이미지의 특성을 반영한 신경망 모델\n",
    "\n",
    "- **Spatially-Local correlation 을 고려하기 위해 sparse connection 구성**\n",
    "  - 인접한 변수만을 이용하여 새로운 feature 생성\n",
    "  \n",
    "- **Invariant feature를 추출하기 위해 shared weight 개념 이용**\n",
    "  - 인접한 변수 집합에는 동일한 weight를 적용 <br/>\n",
    "\n",
    "- 위의 둘을 실현시킨 방법이 convolution layer\n",
    "![](./img/05_convolutional_layer_01.png)\n",
    "<br/>\n",
    "\n",
    "\n",
    "## Convolutional Layer\n",
    "\n",
    "- Filter 가 이미지를 스캔하면서 새로운 변수를 만들어 냄\n",
    "- **Filter = Convolutional layer 의 파라미터 = W = kernel**\n",
    "- 여러 개의 filter로 부터 이미지의 다양한 특성을 추출\n",
    "![](./img/05_convolutional_layer_02.png) \n",
    "<br/>\n",
    "\n",
    "## Convolutional Neural Network (CNN)\n",
    "\n",
    "> LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. *Proceedings of the IEEE, 86(11), 2278-2324*\n",
    "\n",
    "- Convolutional layer를 이용하여 구성한 인공신경망 모델\n",
    "- Convolution - Pooling 의 반복 구조\n",
    "- Pooling : feature 의 down 샘플링\n",
    "- Fully connected layer : 일반적인 인공신경망 연결 구조\n",
    "![](./img/05_convolutional_layer_04.png) \n",
    "\n",
    "* 일반적으로 feature map의 사이즈는 점점 적어지고, feature의 갯수는 점점 늘려가는 구조로 모델링을 하게 됨\n",
    "\n",
    "\n",
    "## Convolution\n",
    "\n",
    "- http://bmia.bmt.tue.nl/education/courses/fev/course/notebooks/Convolution.html (gif 이미지 참조)\n",
    "\n",
    "- 아래의 수식으로 정의된 연산을 convolution (합성곱)이라 함\n",
    "- Filter 가 이미지를 스캔하면서 새로운 변수(값)을 만들어낸 과정과 동일한 연산\n",
    "- 함수 f는 이미지를 g는 filter를 의미\n",
    "$$(f*g)(t) =^{def} \\int_{-\\infty}^{\\infty } f(\\tau )g(t-\\tau)d\\tau $$<br/>\n",
    "$$= \\int_{-\\infty}^{\\infty } f(t-\\tau )g(\\tau)d\\tau $$ <br/>\n",
    "\n",
    "\n",
    "## Convolutional Layer 연산\n",
    "\n",
    "- 모든 채널로부터 얻은 결과값을 합하여 activation 함수에 적용\n",
    "- Filter의 depth는 input의 채널 수에 의해 결정\n",
    "  * image로 부터 다양한 특성을 뽑아 내기 위해서는 filter도 다양하게 많아짐 (예: 귀 filter, 눈 filter)\n",
    "  * 보통 200~500 개의 filter를 사용함\n",
    "  ![](./img/05_convolutional_layer_05.png) \n",
    "  \n",
    "#### 단일 채널 convolution 연산 예시\n",
    "\n",
    "![](./img/05_single_convolution.png) <br/>\n",
    "\n",
    "#### Convolutional Layer 연산 예시\n",
    "\n",
    "- parameter = $(3*3) feature 행렬 * 2채널 * 2 필터 $ = 54개\n",
    "![](./img/05_convolution_06.png) <Br/>\n",
    "- http://cs231n.github.io/convolutional-networks/#conv (git 이미지 참조)\n",
    "$$H_{ij}^{k} = Activation\\left ( \\sum_{c \\in  Channel} (W_{c}^{k} * x_{c})_{ij} = b_{k} \\right )$$\n",
    "\n",
    "\n",
    "## Convolutional Layer의 Hyper Parameter\n",
    "\n",
    "|Filter 크기|Filter 수|Stride|Zero Padding|\n",
    "|:-----------|:---------|:------|:------------|\n",
    "|-Filter의 크기와 모양을 결정 (가로* 세로) |-얼마나 다양한 정보를 추출할 것인지 결정 <br/> -많을 수록 다양성 증가|-Filter가 건너뛰는 픽셀의 수 <br/> - 클수록 듬성듬성 이동| - Convolution 연산의 편의성을 위해 사용 <br/> - Filter 크기 및 수, stride에 따라 결정|\n",
    "\n",
    "\n",
    "## Pooling layer\n",
    "\n",
    "- Feature map의 크기를 줄임\n",
    "- MAX, MIN, Average ...\n",
    "- Pooling size: pooling 연산을 할 영역의 크기 (가로* 세로)\n",
    "- Stride : 한 번에 얼마 만큼 이동할지 결정 (주로 pooling size와 같게 설정)\n",
    "  * 최근에는 pooling lyaer를 쓰지 않는 경향이 있음 (computing 파워가 좋으니 정보 손실을 줄이고자 stride만 쓰는 경향)\n",
    "  ![](./img/05_pooling.png) \n",
    "  <br/>  \n",
    "\n",
    "## CNN 모델 해석\n",
    "$\\frac{W-F+2P}{s} +1 = W'$ <br/><br/>\n",
    "$\\frac{32-F+(2*0)}{1} + 1 = 28 \\rightarrow F= 5 $: Filter Size는 5 by 5\n",
    "\n",
    "- W : 입력 데이터의 가로길이\n",
    "- W' : 출력 데이터의 가로길이\n",
    "- F : 필터 가로 길이\n",
    "- P : zero padding 의 크기 \n",
    "\n",
    "![](./img/05_cnn_LeNet_5.png)\n",
    "An early (Le-Net5) Convolutional Neural Network design, LeNet-5, used for recognition of digits\n",
    "<br/>\n",
    "\n",
    "## Backpropagation in CNN\n",
    "\n",
    "- CNN 의 파라미터 filter와 fully connected layer의 파라미터 W를 학습\n",
    "- 다른 신경망 모델과 마찬가지로 backpropagation algorithm 학습\n",
    "$$art_{W,b}min \\sum_{i} L (Y,F(X;W,b))$$\n",
    "![](./img/05_bp_cnn.png)\n",
    "<br/>\n",
    "\n",
    "## Loss Function\n",
    "\n",
    "\n",
    "* 예측 값과 실제 값의 차이를 측정하는 방법\n",
    "* Regression: mean squared error (MSE)\n",
    "* 정의한 Loss function은 항상 미분가능해야 함\n",
    "  * ~~Regression: MAE (mean absolute error), MAPE (mean absolute percentage error)~~\n",
    "\n",
    "|예측값|실제값|\n",
    "|:----:|:----:|\n",
    "|11|10|\n",
    "|19|20|\n",
    "|30|30|\n",
    "|43|40|\n",
    "|47|50|\n",
    "\n",
    "$\\frac{1}{5}\\sum^{5}_{i=1}(y_{i} - \\hat{y}_{i})^{2}$ <br/>\n",
    "$=\\frac{1}{5}[(10-11)^{2} + (20-19)^{2} + (30-30)^{2} + (40-43)^{2}+(50-47)^{2}]$ <br/>\n",
    "$=\\frac{1}{5}(1+1+0+9+9) = 4$ <br/><br/>\n",
    "\n",
    "\n",
    "* Classficiation: cross entropy\n",
    "* 정의한 Loss function 이 미분 가능해야 함\n",
    "  * ~~Classfication: 0/1-Loss (Acc.)~~\n",
    "\n",
    "|예측값||| |실제값|||\n",
    "|:----:|:----:|:----:|:----:|:----:|:----:|\n",
    "|Class1|Class2|Class3| |Class1|Class2|Class3|\n",
    "|0.3|0.2|0.5| |1|0|0|\n",
    "|0.1|0.8|0.1| |0|1|0|\n",
    "|0.6|0.2|0.2| |1|0|0|\n",
    "|0.1|0.5|0.4| |0|0|1|\n",
    "\n",
    "* 실제값 : One-hot vector 형태로 해당 class 만 1로 표기함 (Demension을 맞춰주기 위해)\n",
    "\n",
    "$-\\sum^{4}_{i=1} ln(\\hat(y)_{i}) * y_{i} = -[ln(0.3) + ln(0.8) + ln(0.6) + ln(0.4)] = 2.85$ <br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "## Chain Rule 복습\n",
    "\n",
    "\n",
    "### 1. 합성함수의 미분규칙\n",
    "\n",
    "$$F(x) = f_{1}(f_{2}(f_{3} \\cdots f_{n}(x))) = f_{1}^{o} f_{2}^{o} \\cdots^{o} f_{n}(x)$$ \n",
    "<br/>\n",
    "$$\\frac{\\partial F}{\\partial a} = \\frac{\\partial F}{\\partial f_{1}} \\frac{\\partial f_{1}}{\\partial f_{2}} \\frac{\\partial f_{2}}{\\partial f_{3}} \\cdots \\frac{\\partial f_{n-1}}{\\partial f_{n}}$$\n",
    "<br/>\n",
    "\n",
    "### 2. Cross entropy loss function & ANN 예제\n",
    "\n",
    "$$\\hat{y} = F(X;W) = \\sigma (\\sigma(XW^{(1)})W^{(2)}) = \\sigma^{o}f_{2}^{o}\\sigma^{o}f_{1}(X)$$ \n",
    "<br/>\n",
    "$$L(W) = y ln \\hat(y) ; cross entropy$$\n",
    "<br/>\n",
    "$$\\frac{\\partial L}{\\partial f_{2}} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\sigma} \\frac{\\partial \\sigma}{\\partial f_{2}} $$\n",
    "<br/>\n",
    "$$\\frac{\\partial L}{\\partial f_{1}} = \\frac{\\partial L}{\\partial \\hat{y}} \\frac{\\partial \\hat{y}}{\\partial \\sigma} \\frac{\\partial \\sigma}{\\partial f_{2}} \\frac{\\partial f_{2}}{\\partial \\sigma} \\frac{\\partial \\sigma}{\\partial f_{1}}$$\n",
    "\n",
    "\n",
    "## Back Propagation Algorithm\n",
    "\n",
    "- 틀린 예측을 바로잡기 위해 파라미터를 순차적으로 수정해 나가는 학습 알고리즘\n",
    "- $net^{(1)}$ : activation function 이전의 값 (= 선형변환)\n",
    "  * Classification 예제 \n",
    "    - Binary classification 일 경우, sigmoid\n",
    "    - Multi classification 일 경우, softmax\n",
    "    - 이진 분류 일 경우에 softmax 를 써도 되는가?\n",
    "      > Output layer '남/여' 구분일 경우, <br/>\n",
    "      > Dense(1, 'sigmoid') - 확률 : P <br/>\n",
    "      > Dense(2, 'softmax') - 단 파라미터가 달라지게 됨 (남 P1, 여 P2) <br/>\n",
    "  * 같은 색은 같은 weight 를 가지는 Convolutional Neural Network\n",
    "  * $\\sigma$ : activation function\n",
    "![](./img/05_bp_algorithm_01.png) <br/>\n",
    "- Convolution layer 의 gradient\n",
    "  - 각각의 weight에 대해서 미분 수행\n",
    "![](./img/05_bp_algorithm_02.png) <br/>\n",
    "\n",
    "- Max pooling layer 의 gradient\n",
    "  - forward path : binary 형태의 weight 구성 (max 값에 대해서는 weight 1, 나머지는 0)\n",
    "  - backward path : weight를 가상으로 가정하고 계산 수행\n",
    "![](./img/05_bp_algorithm_03.png) \n",
    "![](./img/05_bp_algorithm_04.png) <br/>\n",
    "\n",
    "## CNN 구조 결정\n",
    "\n",
    "- 사용자가 선택해야 할 파라미터가 매우 많음\n",
    "- Case Study: AlexNet\n",
    "  - \n",
    "  > ImageNet Classification with Deep Convolutional Neural Networks <br/>\n",
    "  > https://www.nvidia.cn/content/tesla/pdf/machine-learning/imagenet-classification-with-deep-convolutional-nn.pdf \n",
    "\n",
    "\n",
    "### VGGnet \n",
    "> Simonyan, K., & Zisserman, A. (2014) Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv: 1409. 1556 <br/>\n",
    "> - https://arxiv.org/abs/1409.1556 <br/>\n",
    "> - http://www.robots.ox.ac.uk/~vgg/research/very_deep/ \n",
    "\n",
    "- 224 $*$ 224 픽셀 이미지 분류\n",
    "  - 2nd place in ILSVRC 2014\n",
    "  - 3 $*$ 3 필터 사용\n",
    "  - Image size /2 $\\rightarrow$ # filters $*$ !\n",
    "  <br/>\n",
    "- CNN 디자인의 가이드를 제시한 Reference 논문 \n",
    "\n",
    "![](./img/05_vggnet_01.png)\n",
    "  - filter size는 3 $*$ 3 으로 고정 \n",
    "  - \"E\" : convolution 을 여러개 쌓은 블록 형태의 구성 후, filter의 갯수를 2배씩 늘려가는 형태 \n",
    "  - Number of parameters (in milions)\n",
    "  \n",
    "|Network | A, A-LRN | B | C | D | E |\n",
    "|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "|Number of parameters | 133 | 133 | 134 | 138 | 144 |\n",
    "   \n",
    "   - FC-4096 : Fully connected layer (Dense, 4096)\n",
    "  \n",
    "![](./img/05_vggnet_02.png)\n",
    "  - filter : 64\n",
    "  - feature map size를 유지하기 위해서 1$*$1 zero padding을 수행함\n",
    "  - max pooling 후 이미지의 feature map 이 절반으로 줄어들게 됨 (112$*$112)\n",
    "  \n",
    "![](./img/05_vggnet_03.png)\n",
    "  - filter : 128\n",
    "  - filter의 갯수만 달라지고 나머지 옵션은 동일하게 사용하므로 똑같이 적용 됨\n",
    "    - 만약 홀수가 나오게 되면 계산이 어렵기 때문에 zeropadding 등의 resizing 을 수행\n",
    "    \n",
    "![](./img/05_vggnet_04.png)\n",
    "  - filter : 256\n",
    "  - 블락내에서 ($*$3회 반복)\n",
    "![](./img/05_vggnet_05.png)\n",
    "  - filter : 512\n",
    "  - filter의 갯수는 2배, 이미지는 절반\n",
    "    - 홀수가 나와서 더이상 진행되지 않을 때까 Dense Layer를 적용\n",
    "![](./img/05_vggnet_06.png)\n",
    "<br/>\n",
    "\n",
    "\n",
    "### Parameter 갯수 구하기 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parameter 갯수 구하기 예제 (상단부, 하단부)\n",
    "\n",
    "## Input Layer of E\n",
    "in_para_cnt = (3*3) *3 *64\n",
    "# filter size 3 by 3\n",
    "# channel cnt (RGB) : 3\n",
    "# filter cnt : 64\n",
    "print ('Input Layer parameter cnt : ', in_para_cnt)\n",
    "\n",
    "## Output Layer of E\n",
    "# filter size 3 by 3\n",
    "# feature map : 512 - (channel cnt)\n",
    "# filter cnt : 512\n",
    "out_para_cnt = (3*3) * 512 * 512\n",
    "print ('Output Layer parameter cnt : ', out_para_cnt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
